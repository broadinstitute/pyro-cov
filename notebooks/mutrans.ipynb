{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for mutation growth rate paper\n",
    "\n",
    "This notebook generates plots for the [paper/](paper/) directory. This assumes you've alread run\n",
    "```sh\n",
    "make update                       # Downloads data (~1hour).\n",
    "make preprocess                   # Preprocesses data (~3days on a big machine).\n",
    "python mutrans.py --vary-holdout  # Fits and crossvalidates model (~1hour GPU).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from pyro.ops.tensor_utils import convolve\n",
    "from pyrocov import mutrans, pangolin, stats\n",
    "from pyrocov.stats import normal_log10bf\n",
    "from pyrocov.util import (\n",
    "    pretty_print, pearson_correlation, quotient_central_moments, generate_colors\n",
    ")\n",
    "from pyrocov.sarscov2 import GENE_TO_POSITION, GENE_STRUCTURE, aa_mutation_to_position\n",
    "\n",
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 200\n",
    "matplotlib.rcParams[\"axes.edgecolor\"] = \"gray\"\n",
    "matplotlib.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "matplotlib.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "matplotlib.rcParams[\"savefig.pad_inches\"] = 0.01\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Avenir', 'DejaVu Sans']\n",
    "matplotlib.rcParams.update({\n",
    "    # 'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_clades = 5000\n",
    "min_num_mutations = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def load_data():\n",
    "    filename = f\"results/mutrans.data.single.{max_num_clades}.{min_num_mutations}.50.None.pt\"\n",
    "    dataset = torch.load(filename, map_location=\"cpu\")\n",
    "    dataset.update(mutrans.load_jhu_data(dataset))\n",
    "    return dataset\n",
    "dataset = load_data()\n",
    "locals().update(dataset)\n",
    "for k, v in sorted(dataset.items()):\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k} \\t{type(v).__name__} of shape {tuple(v.shape)}\")\n",
    "    else:\n",
    "        print(f\"{k} \\t{type(v).__name__} of size {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dense mapping between fine clades and Pango lineages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} x {} x {} = {}\".format(*weekly_clades.shape, weekly_clades.shape.numel()))\n",
    "print(int(weekly_clades.sum()))\n",
    "print(weekly_clades.ne(0).float().mean().item())\n",
    "print(weekly_clades.ne(0).any(0).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/columns.{max_num_clades}.pkl\", \"rb\") as f:\n",
    "    columns = pickle.load(f)\n",
    "print(\"Loaded data from {} samples\".format(len(columns[\"lineage\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"results/nextclade.counts.pkl\", \"rb\") as f:\n",
    "        all_mutations = pickle.load(f)\n",
    "except Exception:\n",
    "    with open(\"results/stats.pkl\", \"rb\") as f:\n",
    "        all_mutations = pickle.load(f)[\"aaSubstitutions\"]\n",
    "print(f\"Loaded {len(all_mutations)} mutations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checking case count time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_cases, lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"confirmed cases\");\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(weekly_clades.sum(-1), lw=1, alpha=0.5)\n",
    "    plt.yscale(\"symlog\", linthresh=10)\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlim(0, len(weekly_cases) - 1)\n",
    "    plt.xlabel(\"week after 2019-12-01\")\n",
    "    plt.ylabel(\"sequenced samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = set(location_id)\n",
    "N_usa = sum(1 for k in locations if \"/ USA /\" in k)\n",
    "N_uk = sum(1 for k in locations if \"/ United Kingdom /\" in k)\n",
    "N_other = len(locations) - N_usa - N_uk\n",
    "print(N_usa, N_uk, N_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll account for epidemiological dynamics in the form of random drift on top of our logistic growth model. Since random drift is inversely proportional to the local number of infections, we'll need a new data source for the number of infections in each region. We'll use JHU's confirmed case counts time series as a proxy for the number of total infections in each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = torch.load(\"results/mutrans.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in fits:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = list(fits.values())[0]\n",
    "pretty_print(best_fit, max_items=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale `coef` by 1/100 in all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALREADY_SCALED = set()\n",
    "\n",
    "def scale_tensors(x, names={\"coef\"}, scale=0.01, prefix=\"\"):\n",
    "    if id(x) in ALREADY_SCALED:\n",
    "        return\n",
    "    if isinstance(x, dict):\n",
    "        for k, v in list(x.items()):\n",
    "            if k in names:\n",
    "                print(f\"{prefix}.{k}\")\n",
    "                x[k] = v * scale\n",
    "            elif k == \"diagnostics\":\n",
    "                continue\n",
    "            else:\n",
    "                scale_tensors(v, names, scale, f\"{prefix}.{k}\")\n",
    "    ALREADY_SCALED.add(id(x))\n",
    "                \n",
    "scale_tensors(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(best_fit[\"params\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.plot(\n",
    "        best_fit[\"mean\"][\"init_loc\"] + 0 * best_fit[\"median\"][\"init\"],\n",
    "        best_fit[\"median\"][\"init\"],\n",
    "        \"k.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assess model fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(key, fit, filenames=()):\n",
    "    num_nonzero = int(torch.count_nonzero(weekly_clades))\n",
    "    median = fit.get(\"median\", fit.get(\"mean\", {}))\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    time = np.arange(1, 1 + len(fit[\"losses\"]))\n",
    "    plt.plot(fit[\"losses\"], label=\"ELBO loss\")\n",
    "    plt.xlim(0, len(fit[\"losses\"]) - 1)\n",
    "    plt.ylabel(\"ELBO loss\")\n",
    "    plt.xlabel(\"SVI step (duration = {:0.1f} minutes)\".format(fit[\"walltime\"]/60))\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_loss(*list(fits.items())[0], filenames=[\"paper/convergence_loss.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scalars(key, fit, filenames=()):\n",
    "    num_nonzero = int(torch.count_nonzero(weekly_clades))\n",
    "    median = fit.get(\"median\", fit.get(\"mean\", {}))\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    time = np.arange(1, 1 + len(fit[\"losses\"]))\n",
    "    aliases = {\n",
    "        \"init_loc_scale\": r\"$\\widehat\\sigma_1$\",\n",
    "        \"init_scale\": r\"$\\widehat\\sigma_2$\",\n",
    "        \"coef_scale\": r\"$\\widehat\\sigma_3$\",\n",
    "        \"rate_scale\": r\"$\\widehat\\sigma_4$\",\n",
    "    }\n",
    "    locs = []\n",
    "    for name, series in fit[\"series\"].items():\n",
    "        rankby = -torch.tensor(series).log1p().mean().item()\n",
    "        name = aliases.get(name)\n",
    "        if name is not None:\n",
    "            locs.append((name, series, rankby))\n",
    "    locs.sort(key=lambda x: x[-1])\n",
    "    for name, series, _ in locs:\n",
    "        plt.plot(time, series, label=name)\n",
    "    for name, series, _ in locs:\n",
    "        plt.plot(time, series, color=\"white\", lw=3, alpha=0.3, zorder=-1)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\", fontsize=6)\n",
    "    plt.xlabel(\"SVI step (duration = {:0.1f} minutes)\".format(fit[\"walltime\"]/60))\n",
    "    plt.xlim(0, len(fit[\"losses\"]))\n",
    "\n",
    "plot_scalars(*list(fits.items())[0], filenames=[\"paper/convergence.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit[\"mean\"][\"rate\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plusminus(mean, std):\n",
    "    p95 = 1.96 * std\n",
    "    return torch.stack([mean - p95, mean, mean + p95])\n",
    "\n",
    "def generate_rainbow(fit, lineage_names):\n",
    "    rate = fit[\"mean\"][\"rate\"].mean(0)\n",
    "    rates = torch.stack([\n",
    "        rate[clade_id[lineage_to_clade[l]]] for l in lineage_names\n",
    "    ])\n",
    "    C = len(lineage_names)\n",
    "    colors = [None] * C\n",
    "    for c, l in enumerate(rates.sort(0).indices.tolist()):\n",
    "        colors[l] = cm.rainbow(c / (C - 1))\n",
    "    return colors\n",
    "\n",
    "def plot_forecast(\n",
    "    fit,\n",
    "    queries=None,\n",
    "    num_strains=10,\n",
    "    strains=None,\n",
    "    plot_bg=False,\n",
    "    filenames=[],\n",
    "):\n",
    "    if queries is None:\n",
    "        queries = list(location_id)\n",
    "    elif isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    fig, axes = plt.subplots(len(queries), figsize=(8, 0.5 + 2.5 * len(queries)), sharex=True)\n",
    "    if not isinstance(axes, (list, np.ndarray)):\n",
    "        axes = [axes]\n",
    "    dates = matplotlib.dates.date2num(mutrans.date_range(len(fit[\"mean\"][\"probs\"])))\n",
    "    forecast_steps = len(fit[\"mean\"][\"probs\"]) - len(weekly_cases)\n",
    "    assert forecast_steps >= 0\n",
    "    probs = plusminus(fit[\"mean\"][\"probs\"], fit[\"std\"][\"probs\"])  # [3, T, P, L]\n",
    "    padding = 1 + (weekly_cases.mean(0, True) + weekly_cases[-1]) / 2\n",
    "    padding = padding.expand(forecast_steps, -1)\n",
    "    weekly_cases_ = torch.cat([weekly_cases, padding], 0)\n",
    "    weekly_cases_.add_(1)  # avoid divide by zero\n",
    "    predicted = probs * weekly_cases_[..., None]\n",
    "    L = probs.shape[-1]\n",
    "    weekly_lineages = weekly_clades.new_zeros(weekly_clades.shape[:-1] + (L,)).scatter_add_(\n",
    "        -1, clade_id_to_lineage_id.expand_as(weekly_clades), weekly_clades\n",
    "    )\n",
    "    ids = torch.tensor([i for i, name in enumerate(location_id_inv)\n",
    "                        if any(q in name for q in queries)])\n",
    "    rankby = weekly_lineages[:, ids].sum(1)\n",
    "    rankby = rankby.mean(0) + rankby[-1]\n",
    "    strain_ids = rankby.sort(-1, descending=True).indices\n",
    "    strain_ids = strain_ids[:num_strains]\n",
    "    lineage_names = list(lineage_id_inv[x] for x in strain_ids)\n",
    "    colors = generate_rainbow(fit, lineage_names)\n",
    "    assert len(colors) >= num_strains\n",
    "    light = \"#bbbbbb\"\n",
    "    for row, (query, ax) in enumerate(zip(queries, axes)):\n",
    "        ids = torch.tensor([i for i, name in enumerate(location_id_inv) if query in name])\n",
    "        print(f\"{query} matched {len(ids)} regions\")\n",
    "        if plot_bg:\n",
    "            counts = weekly_cases[:, ids].sum(1)\n",
    "            print(f\"{query}: max {counts.max():g}, total {counts.sum():g}\")\n",
    "            counts /= counts.max()\n",
    "            ax.plot(dates[:len(counts)], counts, linestyle=\"-\", color=light, lw=0.8, zorder=-20)\n",
    "            counts = weekly_lineages[:, ids].sum([1, 2])\n",
    "            counts /= counts.max()\n",
    "            ax.plot(dates[:len(counts)], counts, linestyle=\"--\", color=light, lw=1, zorder=-20)\n",
    "        pred = predicted.index_select(-2, ids).sum(-2)\n",
    "        pred /= pred[1].sum(-1, True).clamp_(min=1e-20)\n",
    "        obs = weekly_lineages[:, ids].sum(1)\n",
    "        obs /= obs.sum(-1, True).clamp_(min=1e-9)\n",
    "        for s, color in zip(strain_ids, colors):\n",
    "            lb, mean, ub = pred[..., s]\n",
    "            ax.fill_between(dates, lb, ub, color=color, alpha=0.2, zorder=-10)\n",
    "            ax.plot(dates, mean, color=color, lw=1, zorder=-9)\n",
    "            lineage = lineage_id_inv[s]\n",
    "            ax.plot(dates[:len(obs)], obs[:, s], color=color, lw=0, marker='o', markersize=3,\n",
    "                    label=lineage if row == 0 else None)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_yticks(())\n",
    "        #ax.set_ylabel(query.replace(\" / \", \"\\n\"))\n",
    "        ax.set_ylabel(query)\n",
    "        ax.set_xlim(dates.min(), dates.max())\n",
    "        if row == 0:\n",
    "            ax.legend(loc=\"upper left\", fontsize=8 * (10 / num_strains) ** 0.8)\n",
    "        elif row == 1 and plot_bg:\n",
    "            ax.plot([], linestyle=\"--\", color=light, lw=1, label=\"relative #samples\")\n",
    "            ax.plot([], linestyle=\"-\", color=light, lw=0.8, label=\"relative #cases\")\n",
    "            ax.plot([], lw=0, marker='o', markersize=3, color='gray',\n",
    "                    label=\"observed portion\")\n",
    "            ax.fill_between([], [], [], color='gray', label=\"predicted portion\")\n",
    "            ax.legend(loc=\"upper left\",)\n",
    "    ax.xaxis.set_major_locator(matplotlib.dates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%b %Y\"))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(best_fit,\n",
    "              queries=[\"England\", \"USA / Mass\", \"Brazil\"],\n",
    "              # queries=[\"England\", \"USA / Ca\", \"Brazil\"],\n",
    "              num_strains=20,\n",
    "              filenames=[\"paper/forecast.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(best_fit, queries=[\"England\"], num_strains=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(best_fit, queries=[\"USA / Mass\"], num_strains=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(best_fit, queries=[\"South Africa\"], num_strains=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(best_fit, queries=[\"Brazil\"], num_strains=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prevalence(fit, filenames=()):\n",
    "    rate = fit[\"mean\"][\"rate\"].mean(0)\n",
    "    rate = quotient_central_moments(rate, clade_id_to_lineage_id)[1]\n",
    "    rate = rate - rate[lineage_id[\"A\"]]\n",
    "    R = rate.exp()\n",
    "    probs = fit[\"mean\"][\"probs\"].mean(0)\n",
    "    cases = torch.einsum(\"ps,p->s\", probs, weekly_cases[-2])\n",
    "    cases = cases / mutrans.TIMESTEP\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.scatter(R, cases, lw=0, alpha=0)\n",
    "    for i, name in enumerate(lineage_id_inv):\n",
    "        plt.text(R[i], cases[i], name, fontsize=8, alpha=0.8,\n",
    "                 horizontalalignment=\"center\", verticalalignment=\"center\",)\n",
    "    plt.ylabel(\"confirmed cases / day\")\n",
    "    plt.yscale(\"symlog\")\n",
    "    plt.xscale(\"log\")\n",
    "    #plt.ylim(1, None)\n",
    "    plt.xlim(0.9, None)\n",
    "    lb10 = math.floor(10 * R.min().item())\n",
    "    ub10 = math.ceil(10 * R.max().item())\n",
    "    xticks = [x10 / 10 for x10 in range(lb10, ub10 + 1)]\n",
    "    plt.xticks(xticks, list(map(str, xticks)))\n",
    "    plt.xlabel(\"relative reproduction number $R_{strain} / R_A$\")\n",
    "    plt.title(f\"Growth rate of {len(lineage_id)} PANGO lineages\")\n",
    "    plt.tight_layout()\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_prevalence(best_fit, [\"paper/strain_prevalence.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a CSV with data from figure above\n",
    "# import csv\n",
    "# # First, re-create the data in this cell\n",
    "# rate = best_fit[\"mean\"][\"rate\"].mean(0)\n",
    "# rate = quotient_central_moments(rate, clade_id_to_lineage_id)[1]\n",
    "# rate = rate - rate[lineage_id[\"A\"]]\n",
    "# R = rate.exp()\n",
    "# probs = best_fit[\"mean\"][\"probs\"].mean(0)\n",
    "# cases = torch.einsum(\"ps,p->s\", probs, weekly_cases[-2])\n",
    "# cases = cases / mutrans.TIMESTEP\n",
    "# # Now, write it\n",
    "# filename = 'paper/strain_prevalence_data.csv'\n",
    "# fields = [\"Lineage name\", \"Relative reporoduction number\", \"Confirmed cases / day\"]\n",
    "# with open(filename, 'w') as outfile:\n",
    "#     csvwriter = csv.writer(outfile)\n",
    "#     csvwriter.writerow(fields)\n",
    "#     for i, name in enumerate(lineage_id_inv):\n",
    "#         row = [name, R[i].item(), cases[i].item()]\n",
    "#         csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volcano(mean, std, filenames=(), linthresh=2, top_k=50, sigma=5.0):\n",
    "    xs = mean\n",
    "    ys = mean.abs() / std\n",
    "    assert len(xs) == len(mutations)\n",
    "    y0, y1 = float(ys.min()), float(ys.max())\n",
    "    x0, x1 = float(xs.min()), float(xs.max())\n",
    "    x0 = x0 + 0.01 * (x0 - x1)  # pad\n",
    "    ys, idx = ys.sort(0, descending=True)\n",
    "    xs = xs[idx]\n",
    "    pos = (0 < xs) & (xs < math.inf)\n",
    "    neg = (-math.inf < xs) & (xs < 0)\n",
    "    sig = pos & (ys >= sigma)\n",
    "    insig = neg | (pos & (ys < sigma))\n",
    "    xs_pos, ys_pos, idx_pos = xs[pos], ys[pos], idx[pos]\n",
    "    N = top_k\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"Detected significant increase in growth due to \"\n",
    "              f\"{sig.sum().item()} of {len(mutations)} mutations\")\n",
    "    plt.plot(xs[sig][:N], ys[sig][:N], 'k.', lw=0, markersize=2, zorder=10)\n",
    "    plt.plot(xs[sig][N:], ys[sig][N:], 'k.', lw=0, markersize=2, zorder=10, color=\"#777\")\n",
    "    plt.plot(xs[insig], ys[insig], 'k.', lw=0, markersize=2, zorder=10, color=\"#ccc\")\n",
    "    plt.xlabel(r\"effect size  $R_m/R_{wt}$\")\n",
    "    xticks = [0.85, 0.9, 0.95, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    plt.xticks(list(map(math.log, xticks)), list(map(str, xticks)))\n",
    "    plt.ylabel(\"statistical significance (z-score)\")\n",
    "    rpad = 0.33 if any(\",\" in mutations[i] for i in idx_pos[:N].tolist()) else 0.15\n",
    "    plt.xlim(x0, x1 + (x1 - x0) * rpad)\n",
    "    plt.ylim(0, None)\n",
    "    plt.yscale(\"symlog\", linthresh=linthresh)\n",
    "    yticks = [y for y in [0, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000] if y < y1]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    \n",
    "    p_sig = dist.Normal(torch.zeros(()).double(),1).cdf(torch.tensor(-sigma).double()).item()\n",
    "    plt.plot([0, 0, x1], [y1, sigma, sigma], 'k--', lw=1, alpha=0.2)\n",
    "    plt.plot([x0, 0, 0], [sigma, sigma, 0], 'k-', lw=1, alpha=0.1)\n",
    "    comment_pos = 0.55\n",
    "    if False:\n",
    "        plt.text((1 - comment_pos) * x0 + comment_pos * x1, sigma * 0.9,\n",
    "                 f\"1 in {1/p_sig:0.0f} chance\\nof incorrect sign\",\n",
    "                 fontsize=10, horizontalalignment=\"center\", verticalalignment=\"top\",\n",
    "                 alpha=0.4, zorder=100)\n",
    "        plt.text(-0.015, 200,\n",
    "                 \"positive effect\\non growth rate\",\n",
    "                 fontsize=10, horizontalalignment=\"center\", verticalalignment=\"center\",\n",
    "                 alpha=0.4, zorder=100, rotation=90)\n",
    "        \n",
    "    colors = {\"N\": \"blue\", \"S\": \"red\", \"M\": \"purple\", \"ORF1a\": \"darkgreen\"}\n",
    "    ax = plt.gca()\n",
    "    t = (ax.transScale + ax.transLimits).inverted()\n",
    "    for i in range(N):\n",
    "        x = x1\n",
    "        _, y = t.transform((0, 1 - (i + 1) / (N + 1)))\n",
    "        name = mutations[int(idx_pos[i])]\n",
    "        plt.plot([x, xs_pos[i]], [y, ys_pos[i]], color='gray', lw=0.2)\n",
    "        plt.text(x, y, \" \" + name, color=colors.get(name.split(\":\")[0], \"gray\"),\n",
    "                 fontsize=8, verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "    plt.tight_layout()\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_volcano(best_fit[\"mean\"][\"coef\"], best_fit[\"std\"][\"coef\"], linthresh=2,\n",
    "             filenames=[\"paper/volcano.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a CSV with data from figure above\n",
    "# import csv\n",
    "\n",
    "# # Define variables from previous cell\n",
    "# mean = best_fit[\"mean\"][\"coef\"]\n",
    "# std = best_fit[\"std\"][\"coef\"]\n",
    "# linthresh = 2\n",
    "# sigma = 5\n",
    "# top_k = 50\n",
    "\n",
    "# xs = mean\n",
    "# ys = mean.abs() / std\n",
    "# assert len(xs) == len(mutations)\n",
    "# y0, y1 = float(ys.min()), float(ys.max())\n",
    "# x0, x1 = float(xs.min()), float(xs.max())\n",
    "# x0 = x0 + 0.01 * (x0 - x1)  # pad\n",
    "# ys, idx = ys.sort(0, descending=True)\n",
    "# xs = xs[idx]\n",
    "# pos = (0 < xs) & (xs < math.inf)\n",
    "# neg = (-math.inf < xs) & (xs < 0)\n",
    "# sig = pos & (ys >= sigma)\n",
    "# insig = neg | (pos & (ys < sigma))\n",
    "# xs_pos, ys_pos, idx_pos = xs[pos], ys[pos], idx[pos]\n",
    "# N = top_k\n",
    "\n",
    "# # Write CSV\n",
    "# filename = 'paper/volcano.csv'\n",
    "# fields = [\"Mutation\", \"Effect size Rm / Rwt\", \"Statistical significance (z-score)\"]\n",
    "# with open(filename, 'w') as outfile:\n",
    "#     csvwriter = csv.writer(outfile)\n",
    "#     csvwriter.writerow(fields)\n",
    "#     for i in range(len(xs)):\n",
    "#         row = [mutations[i], xs[i].item(), ys[i].item()]\n",
    "#         csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density(mean, axes=None, *, gene_name=None, kernel_radius=200):\n",
    "    bg_position = torch.tensor([aa_mutation_to_position(m) for m in all_mutations])\n",
    "    fg_position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    assert fg_position.shape == mean.shape\n",
    "    N = 1 + max(fg_position.max().item(), bg_position.max().item(),\n",
    "                max([end for start, end in GENE_TO_POSITION.values()]))\n",
    "    kernel = torch.cat([torch.arange(1, 1.0 + kernel_radius / 2),\n",
    "                        torch.arange(1.0 + kernel_radius / 2, 0, -1)])\n",
    "    kernel = convolve(kernel, kernel)  # smooth out kernel\n",
    "    kernel /= kernel.sum()\n",
    "    def smooth(signal):\n",
    "        result = convolve(kernel, signal)[kernel_radius:-kernel_radius]\n",
    "        assert len(result) == N\n",
    "        return result\n",
    "    background = torch.zeros(N).scatter_add_(0, bg_position, torch.ones(len(bg_position)))\n",
    "    foreground = torch.zeros(N).scatter_add_(0, fg_position, mean.abs())\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(3, figsize=(10, 2.2), sharex=True)\n",
    "    X = torch.arange(N)\n",
    "    Y0 = torch.zeros_like(X)\n",
    "    Y_fg = smooth(foreground)\n",
    "    Y_bg = smooth(background)\n",
    "    Y_ratio = Y_fg / (Y_bg + 1e-3)\n",
    "    y1 = Y_bg.max().item()\n",
    "    axes[0].fill_between(X, Y0, Y_ratio, lw=1, color=\"#009\")\n",
    "    axes[1].fill_between(X, Y0, Y_fg, lw=1, color=\"#005\")\n",
    "    axes[2].fill_between(X, Y0, Y_bg, lw=1, color=\"#555\")\n",
    "    axes[0].set_ylabel(\"ratio\", labelpad=10, fontsize=9)\n",
    "    axes[1].set_ylabel(\"AA Change Density\\ngrowth-\\nrelated\", labelpad=5, fontsize=9)\n",
    "    axes[2].set_ylabel(\"all\", labelpad=10, fontsize=9)\n",
    "    axes[0].set_xlim(0, N)\n",
    "    for ax in axes:\n",
    "        ax.set_yticks(())\n",
    "        ax.set_ylim(0, None)\n",
    "    def axvline(x):\n",
    "        for ax in axes:\n",
    "            ax.axvline(x, lw=0.1, color=\"black\", zorder=-1)\n",
    "            ax.axvline(x, lw=0.1, color=\"white\", alpha=0.5)\n",
    "    if gene_name:\n",
    "        offset = GENE_TO_POSITION[gene_name][0]\n",
    "        for start, end in GENE_STRUCTURE.get(gene_name, {}).values():\n",
    "            axvline(offset + 3 * start)\n",
    "            axvline(offset + 3 * end)\n",
    "    else:  # overview plot\n",
    "        xticks = []\n",
    "        shift = {\"ORF6\": -100, \"ORF7a\": -50, \"ORF8\": 50, \"ORF10\": -50}\n",
    "        for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "            if gene == \"ORF14\":\n",
    "                continue  # skip overlapping frame\n",
    "            axvline(start)\n",
    "            axvline(end)\n",
    "            xticks.extend([start, end])\n",
    "            axes[-1].text((start + end) / 2 + shift.get(gene, 0), -y1 / 10, gene, rotation=-90,\n",
    "                          fontsize=7, verticalalignment=\"top\", horizontalalignment=\"center\")\n",
    "            axes[-1].set_xticks(xticks)\n",
    "            axes[-1].set_xticklabels(())\n",
    "        \n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    \n",
    "plot_density(best_fit[\"mean\"][\"coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_manhattan(mean, top_k=60, filenames=()):\n",
    "    assert len(mean) == len(mutations)\n",
    "    Y = mean\n",
    "    y1 = Y.max().item()\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    radius = 3 + 27 * (Y / Y.max())\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (mean >= 0)\n",
    "\n",
    "    fig, axes = plt.subplots(4, figsize=(10, 5.5), sharex=True,\n",
    "                             gridspec_kw={\"height_ratios\": [8, 1, 1, 1]})\n",
    "    ax = axes[0]\n",
    "    # ax.set_title(f\"Increased growth rate of {len(mutations)} mutations\")\n",
    "    ax.scatter(position[mask].numpy(), Y[mask].numpy(),\n",
    "               radius[mask].numpy(), color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = {\"S\": [], \"N\": [], \"ORF3a\": []}  # Many hits, plot with lines\n",
    "    for i in Y.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(Y[i])\n",
    "        gene, name = mutations[i].split(\":\")\n",
    "        if gene in special:\n",
    "            special[gene].append((y, x, name))\n",
    "            continue\n",
    "        ax.text(x, y + y1/80, name, fontsize=6,\n",
    "                verticalalignment=\"bottom\", horizontalalignment=\"center\")\n",
    "    for special_ in special.values():\n",
    "        special_.sort(reverse=True)\n",
    "    y_bounds = {k: (min(y for (y, _, _) in v), max(y for (y, _, _) in v))\n",
    "                for k, v in special.items() if v}\n",
    "    for i, (y, x, name) in enumerate(special[\"S\"]):\n",
    "        lb, ub = y_bounds[\"S\"]\n",
    "        lb, ub = lb * 0.9, ub * 0.01 + y1 * 0.99\n",
    "        y_label = 0.2 * y + 0.8 * (ub + (lb - ub) * (i / (len(special[\"S\"]) - 0.99)))\n",
    "        x_label = GENE_TO_POSITION[\"S\"][1] - 1100\n",
    "        ax.text(x_label, y_label, name, fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "        ax.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for gene in set(special) - {\"S\"}:\n",
    "        for i, (y, x, name) in enumerate(special[gene]):\n",
    "            lb, ub = y_bounds[gene]\n",
    "            lb, ub = lb * 0.8, ub * 0.1 + y1 * 0.9\n",
    "            y_label = 0.3 * y + 0.7 * (ub + (lb - ub) * (i / (len(special[gene]) - 0.99)))\n",
    "            x_label = GENE_TO_POSITION[gene][1] + 200\n",
    "            ax.text(x_label, y_label, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            ax.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "        \n",
    "    start_end = list(GENE_TO_POSITION.values())\n",
    "    for i, (gene, (start, end)) in enumerate(GENE_TO_POSITION.items()):\n",
    "        if gene == \"ORF14\":\n",
    "            continue  # skip overlapping frame\n",
    "        ax.axvline(start, lw=0.1, color=\"gray\")\n",
    "        ax.axvline(end, lw=0.1, color=\"gray\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_ylim(0, None)\n",
    "    ax.set_ylabel(\"Δ log R\")\n",
    "    for ax in axes:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(0.5)\n",
    "    plot_density(mean, axes[1:])\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_manhattan(best_fit[\"mean\"][\"coef\"], top_k=55, filenames=[\"paper/manhattan.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_manhattan_gene(gene, mean, top_k=200, kernel_radius=100, filenames=()):\n",
    "    assert len(mean) == len(mutations)\n",
    "    Y = mean\n",
    "    position = torch.tensor([aa_mutation_to_position(m) for m in mutations])\n",
    "    gene_id = {gene_name: i for i, gene_name in enumerate(GENE_TO_POSITION)}\n",
    "    gene_ids = torch.tensor([gene_id[m.split(\":\")[0]] for m in mutations])\n",
    "    mask = (gene_ids == gene_id[gene]) & (mean > 0)\n",
    "    y1 = Y[mask].max().item()\n",
    "    radius = 3 + 27 * (Y / Y[mask].max())\n",
    "\n",
    "    fig, axes = plt.subplots(4, figsize=(10, 5.5), sharex=True,\n",
    "                             gridspec_kw={\"height_ratios\": [8, 1, 1, 1]})\n",
    "    ax = axes[0]\n",
    "    ax.set_ylabel(\"Δ log R\")\n",
    "    ax.set_ylim(0, 1.05 * y1)\n",
    "    # ax.set_title(f\"Increased growth rate of mutations within {gene} gene\")\n",
    "    ax.scatter(position[mask].numpy(), Y[mask].numpy(),\n",
    "               radius[mask].numpy(), color=\"darkblue\", alpha=0.5, lw=0)\n",
    "    special = defaultdict(list)  # Many hits, plot with lines\n",
    "    start, end = GENE_TO_POSITION[gene]\n",
    "    zs = {\n",
    "        \"ORF1a\": {\"NSP4\": (2800, 3280), \"NSP6\": (3550, 3800)},\n",
    "        \"ORF1b\": {\"NSP13\": (950, 1450), \"NSP14\": (1450, 1950)},\n",
    "        \"N\": {\"SR\": (180, 240)},\n",
    "        \"S\": {\"NTD\": (20, 250), \"RBD\":  (300, 510), \"FC\": (650, 800), \"HR1\": (900, 980)},\n",
    "    }.get(gene, {})\n",
    "    for i in Y.sort(0, descending=True).indices[:top_k].tolist():\n",
    "        x = float(position[i])\n",
    "        y = float(Y[i])\n",
    "        g, name = mutations[i].split(\":\")\n",
    "        pos = int(re.search(\"[0-9]+\", name).group())\n",
    "        if g != gene:\n",
    "            continue\n",
    "        found = False\n",
    "        for region, (z0, z1) in zs.items():\n",
    "            if z0 < pos < z1:\n",
    "                special[region].append((y, x, name))\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            ax.text(x, y * 1.01 + + y1 / 60, name, fontsize=6,\n",
    "                     verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    for region, hits in special.items():\n",
    "        if not hits:\n",
    "            continue\n",
    "        z0, z1 = zs[region]\n",
    "        hits.sort(reverse=True)\n",
    "        lb = min(y for (y, _, _) in hits)\n",
    "        ub = max(y for (y, _, _) in hits)\n",
    "        lb, ub = lb * 0.5, ub * 0.5 + y1 * 0.5\n",
    "        for i, (y, x, name) in enumerate(hits):\n",
    "            y_label = 0.1 * y + 0.9 * (ub + (lb - ub) * (i / (len(hits) - 0.99)))\n",
    "            x_label = start + 3 * z1\n",
    "            ax.text(x_label, y_label, name, fontsize=6,\n",
    "                    verticalalignment=\"center\", horizontalalignment=\"left\")\n",
    "            ax.plot([x, x_label], [y, y_label], 'k-', lw=0.2, alpha=0.5)\n",
    "    for h_start, h_end in GENE_STRUCTURE.get(gene, {}).values():\n",
    "        ax.axvline(start + 3 * h_start, lw=0.1, color=\"gray\")\n",
    "        ax.axvline(start + 3 * h_end, lw=0.1, color=\"gray\")\n",
    "    plot_density(mean, axes[1:], gene_name=gene, kernel_radius=kernel_radius)\n",
    "    # Plot within-gene coordinates.\n",
    "    ax = axes[-1]\n",
    "    xticks = [start]\n",
    "    dx = 150\n",
    "    while end - start > dx * 12:\n",
    "        dx *= 2\n",
    "    while xticks[-1] + dx < end:\n",
    "        xticks.append(xticks[-1] + dx)\n",
    "    labels = [str((x - start) // 3) for x in xticks]\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel(f\"amino acid position within {gene} gene\")\n",
    "    ax.set_xlim(start, end)\n",
    "    for ax in axes:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(0.5)\n",
    "    ax = axes[-1]\n",
    "    color = \"lightgray\"\n",
    "    for name, (h_start, h_end) in reversed(list(GENE_STRUCTURE.get(gene, {}).items())):\n",
    "        y = 0.32 * ax.get_ylim()[-1]\n",
    "        x0 = start + 3 * h_start\n",
    "        x1 = start + 3 * h_end\n",
    "        ax.fill_between([x0, (x0 + x1) / 2, x1], [0, y, 0], [0, 0, 0],\n",
    "                        color=color, lw=0)\n",
    "        ax.text(start + 3 * (h_start + h_end) / 2, y / 2, name,\n",
    "                ha=\"center\", va=\"center\", fontsize=8,\n",
    "                bbox=dict(boxstyle='round,pad=0.07', fc='lightgray', ec='none'))\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "coef = best_fit[\"mean\"][\"coef\"]\n",
    "plot_manhattan_gene(\"S\", coef, 140, 100, filenames=[\"paper/manhattan_S.png\"])\n",
    "plot_manhattan_gene(\"N\", coef, 500, 50, filenames=[\"paper/manhattan_N.png\"])\n",
    "plot_manhattan_gene(\"ORF3a\", coef, 500, 50, filenames=[\"paper/manhattan_ORF3a.png\"])\n",
    "plot_manhattan_gene(\"ORF1a\", coef, 200, 150, filenames=[\"paper/manhattan_ORF1a.png\"])\n",
    "plot_manhattan_gene(\"ORF1b\", coef, 400, 150, filenames=[\"paper/manhattan_ORF1b.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a table of top mutations and their stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mutations(fit, names):\n",
    "    mean = fit[\"mean\"][\"coef\"]\n",
    "    std = fit[\"std\"][\"coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    ranks = sigma.sort(0, descending=True).indices.tolist()\n",
    "    assert len(ranks) == len(mutations)\n",
    "    ranked = [mutations[k] for k in ranks]\n",
    "    ranks = {m: i for i, m in enumerate(ranked)}\n",
    "    print(\"Mut'n\\tRank\\tEstimate\")\n",
    "    for name in names:\n",
    "        i = mutations.index(name)\n",
    "        print(\"{}\\t{}\\t{:0.3g} ± {:0.2g}\".format(name, ranks[name], mean[i], std[i]))\n",
    "\n",
    "rank_mutations(best_fit, [\"S:D614G\", \"S:N501Y\", \"S:E484K\", \"S:L452R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_features = torch.zeros_like(features)\n",
    "for c, child in enumerate(lineage_id_inv):\n",
    "    child = pangolin.decompress(child)\n",
    "    parent = child\n",
    "    while True:\n",
    "        parent = \"A\" if parent == \"A\" else pangolin.get_parent(parent)\n",
    "        try:\n",
    "            p = lineage_id[pangolin.compress(parent)]\n",
    "            break\n",
    "        except KeyError:\n",
    "            continue\n",
    "    parent_features[c] = features[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emergences(i):\n",
    "    delta = features[:, i] - parent_features[:, i]\n",
    "    emerged = set((delta > 0.5).nonzero(as_tuple=True)[0].tolist())\n",
    "    emerged.add(delta.argmax().item())\n",
    "    result = set()\n",
    "    for k in sorted(emerged):\n",
    "        name = clade_to_lineage[clade_id_inv[k]]\n",
    "        if name == \"XA\":\n",
    "            continue\n",
    "        longname = pangolin.decompress(name)\n",
    "        result.add(name if name == longname else f\"{name} ({longname})\")\n",
    "    return sorted(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_mutation_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    mean = fit[\"mean\"][\"coef\"]\n",
    "    std = fit[\"std\"][\"coef\"]\n",
    "    sigma = mean / std.clamp(min=1e-8)\n",
    "    log10p = normal_log10bf(mean.double().numpy(), std.double().numpy())\n",
    "    if \"samples\" in fit:\n",
    "        lb, ub = stats.confidence_interval(0.95, fit[\"samples\"][\"coef\"])\n",
    "    else:\n",
    "        lb, ub = dist.Normal(mean, std).icdf(torch.tensor([0.025, 0.975])[:, None])\n",
    "    R_RA = mean.exp()  # mean is in units of generation time.\n",
    "    lineage_counts = weekly_clades.sum((0, 1))\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"mutation\", \"{:s}\"),\n",
    "        (\"mean/stddev\", \"{:0.6g}\"),\n",
    "        (\"log10(P(ΔR > 1))\", \"{:0.6g}\"),\n",
    "        (\"Δ log R\", \"{:0.6g}\"),\n",
    "        (\"Δ log R 95% ci lower\", \"{:0.6g}\"),\n",
    "        (\"Δ log R 95% ci upper\", \"{:0.6g}\"),\n",
    "        (\"R / R_A\", \"{:0.6g}\"),\n",
    "        (\"R / R_A 95% ci lower\", \"{:0.6g}\"),\n",
    "        (\"R / R_A 95% ci upper\", \"{:0.6g}\"),\n",
    "        (\"emerged in lineages\", \"{:s}\"),  \n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(sigma.sort(0, descending=True).indices.tolist()):\n",
    "            emerged = find_emergences(i)\n",
    "            f.write(row.format(\n",
    "                rank + 1, mutations[i],\n",
    "                sigma[i], log10p[i], mean[i], lb[i], ub[i], R_RA[i], lb[i].exp(), ub[i].exp(),\n",
    "                \", \".join(emerged)\n",
    "            ))\n",
    "\n",
    "write_mutation_table(best_fit, \"paper/mutations.tsv\")\n",
    "df = pd.read_csv(\"paper/mutations.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table_1(df, num_rows=20, filenames=()):\n",
    "    df = df[:num_rows]\n",
    "    df2 = df[[\"rank\"]].copy()\n",
    "    df2[\"Gene\"] = [x.split(\":\")[0] for x in df[\"mutation\"]]\n",
    "    df2[\"Substitution\"] = [x.split(\":\")[1] for x in df[\"mutation\"]]\n",
    "    df2[\"Fold Increase\\nin Fitness\"] = [f\"{x:0.3f}\" for x in df[\"R / R_A\"]]\n",
    "    df2[\"Number of\\nLineages\"] = [x.count(\",\") for x in df[\"emerged in lineages\"]]\n",
    "    df2.rename(columns={\"rank\": \"Rank\"}, inplace=True)\n",
    "    for f in filenames:\n",
    "        df2.to_csv(f, sep=\"\\t\")\n",
    "    return df2\n",
    "\n",
    "save_table_1(df, filenames=[\"paper/table_1.tsv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_lineage_bdays(exclude_first=10, min_portion=0.0005, max_portion=0.1):\n",
    "    lineage_days = defaultdict(list)\n",
    "    for lineage, day in zip(columns[\"lineage\"], columns[\"day\"]):\n",
    "        if lineage is None:\n",
    "            continue\n",
    "        lineage = pangolin.decompress(lineage)\n",
    "        lineage_days[lineage].append(day)\n",
    "    lineage_bday = {}\n",
    "    for lineage, days in list(lineage_days.items()):\n",
    "        days.sort()\n",
    "        exclude = max(exclude_first, int(min_portion * len(days)))\n",
    "        exclude = min(exclude, int(max_portion * len(days)))\n",
    "        lineage_bday[lineage] = days[exclude]\n",
    "    start_date = datetime.datetime.strptime(mutrans.START_DATE, \"%Y-%m-%d\")\n",
    "    result = {\n",
    "        lineage: (start_date + datetime.timedelta(days=day))\n",
    "        for lineage, day in lineage_bday.items()\n",
    "    }\n",
    "    # Clamp parent to earlier than descendents.\n",
    "    for child in reversed(list(result)):\n",
    "        parent = pangolin.get_parent(pangolin.decompress(child))\n",
    "        if parent is not None:\n",
    "            parent = pangolin.compress(parent)\n",
    "            if parent in result:\n",
    "                result[parent] = min(result[child], result[parent])\n",
    "            else:\n",
    "                result[parent] = result[child]\n",
    "    return result\n",
    "\n",
    "lineage_bday = estimate_lineage_bdays()\n",
    "\n",
    "def get_lineage_bday(name):\n",
    "    name = pangolin.decompress(name)\n",
    "    if name not in lineage_bday:\n",
    "        lineage_bday[name] = get_lineage_bday(pangolin.get_parent(name))\n",
    "    return lineage_bday[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_strain_table(fit, filename):\n",
    "    assert filename.endswith(\".tsv\")\n",
    "    mm = quotient_central_moments(fit[\"mean\"][\"rate\"].mean(0), clade_id_to_lineage_id)\n",
    "    ms = quotient_central_moments(fit[\"mean\"][\"rate\"].std(0), clade_id_to_lineage_id)\n",
    "    sm = quotient_central_moments(fit[\"std\"][\"rate\"].mean(0), clade_id_to_lineage_id)\n",
    "    rate_std = (mm[2].square() + ms[1].square() + sm[1].square()).sqrt().clamp(min=1e-3)\n",
    "    rate_mean = mm[1]\n",
    "    sigma = rate_mean / rate_std.clamp(min=1e-8)\n",
    "    log10p = normal_log10bf(rate_mean.double().numpy(), rate_std.double().numpy())\n",
    "    R_mean = rate_mean.exp()\n",
    "    lb, ub = dist.Normal(rate_mean, rate_std).icdf(torch.tensor([0.025, 0.975])[..., None])\n",
    "    RA = R_mean[lineage_id[\"A\"]].item()\n",
    "    R_RA = R_mean / RA\n",
    "    lb = lb.exp() / RA\n",
    "    ub = ub.exp() / RA\n",
    "    probs = fit[\"median\"][\"probs\"][:len(weekly_cases)]\n",
    "    cases = torch.einsum(\"tps,tp->ts\", probs, weekly_cases)\n",
    "    cases_per_day = cases[-2] / mutrans.TIMESTEP\n",
    "    cases_total = cases.sum(0)\n",
    "    schema = [\n",
    "        (\"rank\", \"{:d}\"),\n",
    "        (\"strain\", \"{:s}\"),\n",
    "        (\"mean/stddev\", \"{:.6g}\"),\n",
    "        (\"log10(P(R > R_A))\", \"{:0.6g}\"),\n",
    "        (\"R / R_A\", \"{:.6g}\"),\n",
    "        (\"R / R_A 95% ci lower\", \"{:.6g}\"),\n",
    "        (\"R / R_A 95% ci upper\", \"{:.6g}\"),\n",
    "        (\"confirmed cases / day\", \"{:.6g}\"),\n",
    "        (\"confirmed cases total\", \"{:.6g}\"),\n",
    "        (\"birthday\", \"{:s}\"),\n",
    "        (\"mutations\", \"{:s}\"),\n",
    "    ]\n",
    "    header = \"\\t\".join(h for h, r in schema) + \"\\n\"\n",
    "    row = \"\\t\".join(r for h, r in schema) + \"\\n\"\n",
    "    columns = {h: [] for h, _ in schema}\n",
    "    with open(filename, \"wt\") as f:\n",
    "        f.write(header)\n",
    "        for rank, i in enumerate(R_RA.sort(0, descending=True).indices.tolist()):\n",
    "            lineage = lineage_id_inv[i]\n",
    "            clade = lineage_to_clade[lineage]\n",
    "            clade_id = torch.tensor([1 if c == clade else 0 for c in clade_id_inv]).nonzero(as_tuple=True)[0]\n",
    "            lineage_mutations = []\n",
    "            lineage_mutations = [mutations[m] for m in features[clade_id].nonzero(as_tuple=True)[1].tolist()]\n",
    "            lineage_mutations = \",\".join(set(lineage_mutations))  # Unique mutations across all clades in the lineage\n",
    "            \n",
    "            values = (\n",
    "                rank + 1, lineage,\n",
    "                sigma[i], log10p[i], R_RA[i], lb[i], ub[i], cases_per_day[i], cases_total[i],\n",
    "                get_lineage_bday(lineage).strftime(\"%Y-%m-%d\"), lineage_mutations,\n",
    "            )\n",
    "            f.write(row.format(*values))\n",
    "            for v, vs in zip(values, columns.values()):\n",
    "                vs.append(v)\n",
    "    return columns\n",
    "\n",
    "strain_table = write_strain_table(best_fit, \"paper/strains.tsv\")\n",
    "pd.read_csv(\"paper/strains.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emergence(fit, inset_rows=10, filenames=()):\n",
    "    rate = quotient_central_moments(fit[\"mean\"][\"rate\"].mean(0), clade_id_to_lineage_id)[1]\n",
    "    rate = rate - rate[lineage_id[\"A\"]]\n",
    "    R = rate.exp()\n",
    "    probs = fit[\"mean\"][\"probs\"][:len(weekly_cases)]\n",
    "    cases = torch.einsum(\"tps,tp->s\", probs, weekly_cases)\n",
    "    cases = cases / mutrans.TIMESTEP\n",
    "    bday = [get_lineage_bday(s) for s in lineage_id_inv]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    voc_mask = torch.zeros(len(lineage_id_inv), dtype=torch.bool)\n",
    "    for voc in pangolin.WHO_VOC:\n",
    "        for prefix in pangolin.WHO_ALIASES[voc]:\n",
    "            for name, i in lineage_id.items():\n",
    "                if name == prefix or name.startswith(prefix + \".\"):\n",
    "                    voc_mask[i] = True\n",
    "    voi_mask = torch.zeros(len(lineage_id_inv), dtype=torch.bool)\n",
    "    for voi in pangolin.WHO_VOI:\n",
    "        for prefix in pangolin.WHO_ALIASES[voi]:\n",
    "            for name, i in lineage_id.items():\n",
    "                if name == prefix or name.startswith(prefix + \".\"):\n",
    "                    voi_mask[i] = True\n",
    "    non_mask = ~(voc_mask | voi_mask)\n",
    "    scale = 4e5 / fit[\"weekly_cases\"].sum().item()\n",
    "    for mask, color, label in [\n",
    "        (non_mask, \"black\", \"1 million cases\"),\n",
    "        (voi_mask, \"green\", \"Variant of Interest\"),\n",
    "        (voc_mask, \"red\", \"Variant of Concern\"),\n",
    "    ]:\n",
    "        bday_mask = [b for b, m in zip(bday, mask) if m]\n",
    "        plt.scatter([], [], 1e6 * scale, color=color, alpha=0.3,\n",
    "                    label=label)\n",
    "        plt.scatter(bday_mask, R[mask], cases[mask] * scale + 0.5, color=color, alpha=0.3, lw=0.5)\n",
    "    for name, i in lineage_id.items():\n",
    "        if cases[i] < 1e6 and name not in [\"B.1.1.529\", \"BA.1\", \"BA.2\"]:\n",
    "            continue\n",
    "        if voi_mask[i]:\n",
    "            plt.text(bday[i], R[i], name, fontsize=8, alpha=0.8, color=\"darkgreen\",\n",
    "                     ha=\"center\", va=\"center\", zorder=2)\n",
    "        elif voc_mask[i]:\n",
    "            plt.text(bday[i], R[i], name, fontsize=8, alpha=0.8, color=\"darkred\",\n",
    "                     ha=\"center\", va=\"center\", zorder=3)\n",
    "        elif R[i] > 1.81:\n",
    "            plt.text(bday[i], R[i], name, fontsize=8, alpha=0.6, color=\"black\",\n",
    "                     ha=\"center\", va=\"center\", zorder=1)\n",
    "    plt.ylabel(\"$R / R_A$\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Date of Lineage Emergence\")\n",
    "    lb10 = math.floor(5 * R.min().item())\n",
    "    ub10 = math.ceil(5 * R.max().item()) + 1\n",
    "    #yticks = [y10 / 5 for y10 in range(lb10, ub10 + 2)]\n",
    "    yticks = [0.8, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
    "    plt.yticks(yticks, list(map(str, yticks)))\n",
    "    plt.ylim(0.9, ub10 / 5)\n",
    "    x0, x1 = min(bday), max(bday)\n",
    "    dx = x1 - x0\n",
    "    plt.xlim(x0 - 0.025 * dx, x1 + dx * 0.025)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if False:\n",
    "        for lineage in [\"B.1.1.529\"]:\n",
    "            i = strain_table[\"strain\"].index(\"B.1.1.529\")\n",
    "            lb = strain_table[\"R / R_A 95% ci lower\"][i]\n",
    "            ub = strain_table[\"R / R_A 95% ci upper\"][i]\n",
    "            x = bday[lineage_id[lineage]]\n",
    "            plt.plot([x - dx/100, x + dx/100], [ub, ub], \"r-\")\n",
    "            plt.plot([x - dx/100, x + dx/100], [lb, lb], \"r-\")\n",
    "    if inset_rows:\n",
    "        strain = strain_table[\"strain\"][:inset_rows]\n",
    "        RRa = strain_table[\"R / R_A\"][:inset_rows]\n",
    "        lb = strain_table[\"R / R_A 95% ci lower\"][:inset_rows]\n",
    "        ub = strain_table[\"R / R_A 95% ci upper\"][:inset_rows]\n",
    "        cases_per_day = strain_table[\"confirmed cases / day\"][:inset_rows]\n",
    "        color = \"#666666\"\n",
    "        y_line = ub10 / 5 - 1\n",
    "        plt.plot([x0 - 0.01 * dx, x0 + 0.34 * dx], [y_line, y_line], \"k-\", lw=0.5,\n",
    "                 color=color)\n",
    "        style = dict(va=\"bottom\", ha=\"left\", fontsize=9, color=color)\n",
    "        y = y_line * 1.001\n",
    "        plt.text(x0, y, \"Lineage\", **style)\n",
    "        plt.text(x0 + 0.1 * dx, y, \"$R/R_A$ (95% CI)\", **style)\n",
    "        plt.text(x0 + 0.25 * dx, y, \"Cases/day\", **style)\n",
    "        style[\"va\"] = \"top\"\n",
    "        y = y_line * 0.991\n",
    "        plt.text(x0, y, \"\\n\".join(strain), **style)\n",
    "        plt.text(x0 + 0.1 * dx, y, \"\\n\".join(\n",
    "            f\"{a:0.2f} ({b:0.2f}—{c:0.2f})\"\n",
    "            for a, b, c in zip(RRa, lb, ub)\n",
    "        ), **style)\n",
    "        style[\"ha\"] = \"right\"\n",
    "        plt.text(x0 + 0.33 * dx, y, \"\\n\".join(f\"{int(c):,}\" for c in cases_per_day), **style)\n",
    "    plt.tight_layout(pad=0)\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "plot_emergence(best_fit, filenames=[\"paper/strain_emergence.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lineage_heterogeneity(fit, top_k=20, filenames=()):\n",
    "    clade_rate = fit[\"mean\"][\"rate\"].mean(0)\n",
    "    clade_rate = clade_rate - clade_rate[clade_id[lineage_to_clade[\"A\"]]]\n",
    "    clade_std = (fit[\"std\"][\"rate\"].mean(0).square()\n",
    "                 + fit[\"std\"][\"rate\"].std(0).square()).sqrt()\n",
    "    abs_rate = clade_rate.abs()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.yscale(\"log\")\n",
    "    # Compute central moments within each lineage.\n",
    "    moments = quotient_central_moments(clade_rate, clade_id_to_lineage_id)\n",
    "    # Plot the most heterogeneous lineages.\n",
    "    most_heterogeneous = moments[2].sort(descending=True).indices\n",
    "    X, Y, labels = [], [], []\n",
    "    for i in most_heterogeneous[:top_k].tolist():\n",
    "        cs = clade_id_to_lineage_id.eq(i).nonzero(as_tuple=True)[0]\n",
    "        Y.append(clade_rate[cs].exp())\n",
    "        X.extend([lineage_id_inv[i]] * len(Y[-1]))\n",
    "        label = lineage_id_inv[i]\n",
    "        labels.append(label)\n",
    "        k = {\"B.1.1\": 4, \"B.1\": 1}.get(label, 0)\n",
    "        if k:\n",
    "            ys, js = Y[-1].topk(k, 0)\n",
    "            y_old = math.inf\n",
    "            for y, j in zip(ys, js):\n",
    "                y = float(y)\n",
    "                y, y_old = min(y, y_old - 0.3), y\n",
    "                c = int(cs[j])\n",
    "                c0 = lineage_id_to_clade_id[i]\n",
    "                delta = features[c] - features[c0]\n",
    "                ms = delta.nonzero(as_tuple=True)[0].tolist()\n",
    "                ms.sort(key=fit['mean']['coef'].__getitem__, reverse=True)\n",
    "                ms = [(\"+\" if delta[m] > 0 else \"-\") + mutations[m][2:]\n",
    "                      for m in ms if mutations[m].startswith(\"S\")]\n",
    "                diff = \"\".join(ms[:5])\n",
    "                x = len(labels) - 0.85\n",
    "                plt.text(x, y, diff + \"...\", va=\"center\", ha=\"left\", fontsize=5, alpha=0.6)\n",
    "    Y = torch.cat(Y)\n",
    "    sns.swarmplot(x=X, y=Y.numpy(), s=3, order=labels)\n",
    "    plt.xticks(range(len(labels)), labels=labels, rotation=-90, fontsize=9,\n",
    "              horizontalalignment=\"center\")\n",
    "    lb = int(math.floor(Y.min() * 2))\n",
    "    ub = int(math.ceil(Y.max() * 2))\n",
    "    yticks = [y / 2 for y in range(lb, 1 + ub)]\n",
    "    plt.yticks(yticks, map(str, yticks))\n",
    "    plt.ylim(0.9 * Y.min().item(), 1.1 * Y.max().item())\n",
    "    plt.ylabel(\"$R_{clade}/R_A$\")\n",
    "    plt.title(\"PANGO lineages with most heterogeneous growth rate estimates\")\n",
    "    plt.tight_layout()\n",
    "    for filename in filenames:\n",
    "        plt.savefig(filename)\n",
    "    \n",
    "plot_lineage_heterogeneity(best_fit, filenames=[\"paper/lineage_heterogeneity.png\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with deep mutational scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compare with [(Starr et al. 2020)](https://www.sciencedirect.com/science/article/pii/S0092867420310035) who study S mutations affecting folding and ACE2 binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mutation-studies/1-s2.0-S0092867420310035-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folding = {f\"S:{m}\": float(e) for m, e in zip(df[\"mutation\"], df[\"expr_avg\"])}\n",
    "binding = {f\"S:{m}\": float(b) for m, b in zip(df[\"mutation\"], df[\"bind_avg\"])}\n",
    "print(sum(1 for m in mutations if m in folding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compare with [(Greaney et al. 2021)](https://www.sciencedirect.com/science/article/pii/S1931312820306247) who study antibody escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mutation-studies/1-s2.0-S1931312820306247-mmc2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escape = {\n",
    "    f\"S:{w}{s}{m}\": float(e)\n",
    "    for w, s, m, e in zip(df[\"wildtype\"], df[\"site\"], df[\"mutation\"], df[\"mut_escape\"])\n",
    "}\n",
    "print(sum(1 for m in mutations if m in escape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "ms = [m for m in mutations if m in escape]\n",
    "y = best_fit[\"mean\"][\"coef\"][[i for i, m in enumerate(mutations) if m in escape]].numpy()\n",
    "axes[0].set_ylabel(\"Δ log R\")\n",
    "for name, ax in zip([\"folding\", \"binding\", \"escape\"], axes):\n",
    "    scan = locals()[name]\n",
    "    x = torch.tensor([scan[m] for m in ms]).numpy()\n",
    "    # ax.scatter(x, y, alpha=0.5, lw=0)\n",
    "    for xm, ym, m in zip(x, y, ms):\n",
    "        ax.text(xm, ym, m[2:], fontsize=6,\n",
    "                verticalalignment=\"center\", horizontalalignment=\"center\")\n",
    "    ax.set_xlim(1.08 * x.min() - 0.08 * x.max(), 1.08 * x.max() - 0.08 * x.min())\n",
    "    ax.set_ylim(1.05 * y.min() - 0.05 * y.max(), 1.05 * y.max() - 0.05 * y.min())\n",
    "    ax.set_xlabel(f\"{name} (ρ = {pearson_correlation(x, y):0.2g})\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(0.5)\n",
    "axes[2].set_xscale(\"log\")\n",
    "axes[2].set_xlim(x.min() ** 1.08 / x.max() ** 0.08, x.max() ** 1.08 / x.min() ** 0.08)\n",
    "axes[1].set_title(f\"Comparison of {len(ms)} S gene mutations to deep scanning\")\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.savefig(\"paper/deep_scanning.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether these correlations are meaningful, as they are dominated by a few outliers.\n",
    "\n",
    "Let's fit a linear model regressing growth rate against theses deep scanning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "def fit_model(fit):\n",
    "    trans_data = fit[\"mean\"][\"coef\"][[i for i, m in enumerate(mutations) if m in escape]]\n",
    "    folding_data = torch.tensor([folding[m] for m in ms])\n",
    "    binding_data = torch.tensor([binding[m] for m in ms])\n",
    "    escape_data = torch.tensor([escape[m] for m in ms])\n",
    "    \n",
    "    def model():\n",
    "        coef = pyro.sample(\"coef\", dist.Normal(0, 10).expand([5]).to_event(1))\n",
    "        t, f, b, e, be = coef.unbind(-1)\n",
    "        noise = pyro.sample(\"noise\", dist.LogNormal(0, 2))\n",
    "        with pyro.plate(\"data\", len(trans_data)):\n",
    "            pred = (\n",
    "                t + f * folding_data + b * binding_data + e * escape_data\n",
    "                + be * binding_data * escape_data\n",
    "            )\n",
    "            pyro.sample(\"trans\", dist.Normal(pred, noise), obs=trans_data)\n",
    "\n",
    "    pyro.clear_param_store()\n",
    "    guide = AutoMultivariateNormal(model)\n",
    "    elbo = Trace_ELBO(num_particles=100, vectorize_particles=True)\n",
    "    svi = SVI(model, guide, Adam({\"lr\": 0.2}), elbo)\n",
    "    for step in range(201):\n",
    "        loss = svi.step()\n",
    "        if step % 20 == 0:\n",
    "            print(f\"step {step} loss = {loss:0.4g}\")\n",
    "    loc, scale = guide._loc_scale()\n",
    "    print(\"Model:\")\n",
    "    print(\"growth rate = t + f folding + b binding + e escape + be binding escape\")\n",
    "    print(\"Learned coefficients:\")\n",
    "    for k, l, s in zip(\"t f b e be\".split(), loc.tolist(), scale.tolist()):\n",
    "        print(f\"{k} = {l:0.4g} +- {s:0.2f}\")\n",
    "        \n",
    "fit_model(best_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit on subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Counter([n for n in columns[\"virus_name\"] if \"-CDC-2-\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"USA\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"United King\" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"North America \" in n]).most_common(2))\n",
    "print(Counter([n for n in columns[\"location\"] if \"Europe \" in n]).most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_fits = {k[-1]: v for k, v in fits.items() if k[-1]}\n",
    "for key in holdout_fits:\n",
    "    print(key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases = [\n",
    "    \"full data\",\n",
    "    \"only Europe\",\n",
    "    \"excluding Europe\",\n",
    "    # \"only North America\",\n",
    "    # \"excluding North America\",\n",
    "    # \"only the USA\",\n",
    "    # \"excluding the USA\",\n",
    "    # \"excluding the UK\",\n",
    "    # \"only the UK\",\n",
    "    # \"only CDC data\",\n",
    "    # \"only CDC NS3 data\",\n",
    "]\n",
    "holdout_fits = dict(zip(aliases, [best_fit] + list(holdout_fits.values())))\n",
    "assert len(holdout_fits) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_agreements(holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        return fit[\"mean\"][\"coef\"]\n",
    "    (name0, fit0), (name1, fit1), (name2, fit2) = holdouts.items()\n",
    "    pairs = [\n",
    "        [(name0, fit0), (name1, fit1)],\n",
    "        [(name0, fit0), (name2, fit2)],\n",
    "        [(name1, fit1), (name2, fit2)],\n",
    "    ]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in means)\n",
    "    x1 = max(mean.max().item() for mean in means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    fig.suptitle(\"Δ log R for {} mutations estimated from subsets of data\"\n",
    "                 .format(len(list(holdouts.values())[0][\"mutations\"])))\n",
    "    for ax, ((name1, fit1), (name2, fit2)) in zip(axes, pairs):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = []\n",
    "        for fit in (fit1, fit2):\n",
    "            m_to_i = {m: i for i, m in enumerate(fit[\"mutations\"])}\n",
    "            idx = torch.tensor([m_to_i[m] for m in mutations])\n",
    "            means.append(get_mean(fit)[idx])\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(pearson_correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_ylim(lb, ub)\n",
    "        ax.set_xlabel(name2)\n",
    "        ax.set_ylabel(name1)\n",
    "    plt.subplots_adjust(wspace=0.12)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_mutation_agreements(holdout_fits, [\"paper/mutation_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_agreements(fit1, holdouts, filenames=()):\n",
    "    def get_mean(fit):\n",
    "        rate = fit[\"mean\"][\"rate\"].mean(0)\n",
    "        rate = quotient_central_moments(rate, clade_id_to_lineage_id)[1]\n",
    "        return (rate - rate[lineage_id[\"A\"]]).exp()\n",
    "    (name0, fit0), (name1, fit1), (name2, fit2) = holdouts.items()\n",
    "    pairs = [\n",
    "        [(name0, fit0), (name1, fit1)],\n",
    "        [(name0, fit0), (name2, fit2)],\n",
    "        [(name1, fit1), (name2, fit2)],\n",
    "    ]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 3), sharey=True)\n",
    "    means = [get_mean(fit) for fit in holdouts.values()]\n",
    "    x0 = min(mean.min().item() for mean in means)\n",
    "    x1 = max(mean.max().item() for mean in means)\n",
    "    lb = 1.05 * x0 - 0.05 * x1\n",
    "    ub = 1.05 * x1 - 0.05 * x0\n",
    "    fig.suptitle(\"$R_{{lineage}} / R_A$ for {} lineages estimated from subsets of data\"\n",
    "                 .format(len(lineage_id)))\n",
    "    for ax, ((name1, fit1), (name2, fit2)) in zip(axes, pairs):\n",
    "        mutations = sorted(set(fit1[\"mutations\"]) & set(fit2[\"mutations\"]))\n",
    "        means = [get_mean(fit) for fit in (fit1, fit2)]\n",
    "        ax.plot([lb, ub], [lb, ub], 'k--', alpha=0.3, zorder=-100)\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 50, alpha=1, lw=0, color=\"white\")\n",
    "        ax.scatter(means[1].numpy(), means[0].numpy(), 30, alpha=0.3, lw=0, color=\"darkred\")\n",
    "        ax.text(x0, 0.05 * x0 + 0.95 * x1,\n",
    "                \"ρ = {:0.2g}\".format(pearson_correlation(means[0], means[1])))\n",
    "        ax.set_xlim(lb, ub)\n",
    "        ax.set_ylim(lb, ub)\n",
    "        ax.set_xlabel(name1)\n",
    "        ax.set_ylabel(name2)\n",
    "    plt.subplots_adjust(wspace=0.12)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "plot_strain_agreements(best_fit, holdout_fits, [\"paper/lineage_agreement.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutation_subset_boxplot(fits, rankby=\"s\", top_k=20, filenames=()):\n",
    "    best_fit = list(fits.values())[1]\n",
    "    if rankby == \"s\":\n",
    "        rankby = best_fit[\"mean\"][\"coef\"] / best_fit[\"std\"][\"coef\"]\n",
    "        title = f\"Top {top_k} most statistically significant mutations\"\n",
    "    elif rankby == \"t\":\n",
    "        rankby = best_fit[\"mean\"][\"coef\"]\n",
    "        title = f\"Top {top_k} mutations associated with increased growth rate\"\n",
    "    else: raise ValueError(rankby)\n",
    "    top_indices = rankby.sort(0, descending=True).indices[:top_k]\n",
    "    top_mutations = [mutations[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        if \"samples\" in fit:\n",
    "            samples = fit[\"samples\"][\"coef\"].T[top_indices].T\n",
    "        else:\n",
    "            mean = fit[\"mean\"][\"coef\"][top_indices]\n",
    "            std = fit[\"std\"][\"coef\"][top_indices]\n",
    "            samples = dist.Normal(mean, std).sample((1000,))\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean(0)\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "    \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    darkcolors = ['blue', 'red', 'green']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "        patch.set_edgecolor(darkcolors[i % len(fits)])\n",
    "    for i, patch in enumerate(boxplot['whiskers']):\n",
    "        patch.set_color(darkcolors[i % len(fits)])\n",
    "    for i, patch in enumerate(boxplot['caps']):\n",
    "        patch.set_color(darkcolors[i // 2 % len(fits)])\n",
    "    for name, c in zip(fits, darkcolors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 9})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               # labels=[x.replace(\":\", \":\\n\") for x in top_mutations],\n",
    "               labels=top_mutations, rotation=-90, fontsize=9)\n",
    "    plt.ylabel(\"effect size  (Δ log R)\")\n",
    "    plt.title(title)\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    for rankby in [\"t\", \"s\"]:\n",
    "        plot_mutation_subset_boxplot(\n",
    "            {\n",
    "                f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "                \"World\": best_fit,\n",
    "                f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "            }, \n",
    "            rankby=rankby,\n",
    "            filenames=[f\"paper/mutation_{name_}_boxplot_rankby_{rankby}.png\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_mutations(rankby=\"s\", top_k=20, restrict_to=\"S:\"):\n",
    "    if rankby == \"s\":\n",
    "        rankby = best_fit[\"mean\"][\"coef\"] / best_fit[\"std\"][\"coef\"]\n",
    "        title = f\"Top {top_k} most statistically significant mutations\"\n",
    "    elif rankby == \"t\":\n",
    "        rankby = best_fit[\"mean\"][\"coef\"]\n",
    "        title = f\"Top {top_k} mutations associated with increased growth rate\"\n",
    "    else: raise ValueError(rankby)\n",
    "    indices = rankby.sort(0, descending=True).indices\n",
    "    top_mutations = [mutations[i] for i in indices.tolist()]\n",
    "    if restrict_to:\n",
    "        top_mutations = [\n",
    "            m[len(restrict_to):] for m in top_mutations if m.startswith(restrict_to)\n",
    "        ]\n",
    "    return top_mutations[:top_k]\n",
    "\n",
    "def print_top_mutations(*args, **kwargs):\n",
    "    print(\"\\n\".join(get_top_mutations(*args, **kwargs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_mutations(\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_mutations(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(sorted(set(get_top_mutations(\"s\", 10)) | set(get_top_mutations(\"t\", 10)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_mutations(\"t\", 100, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strain_subset_boxplot(fits, top_k=20, filenames=()):\n",
    "    def get_rate(stats):\n",
    "        rate = stats[\"rate\"]\n",
    "        if rate.dim() == 2:\n",
    "            rate = rate.mean(0)\n",
    "        return quotient_central_moments(rate, clade_id_to_lineage_id)[1]\n",
    "    best_fit = list(fits.values())[1]\n",
    "    top_indices = get_rate(best_fit[\"median\"]).sort(0, descending=True).indices[:top_k]\n",
    "    top_lineages = [lineage_id_inv[i] for i in top_indices.tolist()]\n",
    "    xscale = 0.6\n",
    "    positions = (torch.arange(top_k)[:, None] * (len(fits) + 1)\n",
    "                 + torch.arange(len(fits))).reshape(-1) * xscale\n",
    "    data = [None] * top_k * len(fits)\n",
    "    lines = [None] * top_k * (len(fits) + 1)\n",
    "    for j, fit in enumerate(fits.values()):\n",
    "        mean = get_rate(fit[\"median\"])[top_indices]\n",
    "        std =  fit[\"median\"][\"rate_scale\"]\n",
    "        samples = dist.Normal(mean, std).sample((1000,))\n",
    "        samples = samples - get_rate(fit[\"median\"])[lineage_id[\"A\"]]\n",
    "        samples = samples.exp()\n",
    "        for i in range(top_k):\n",
    "            data[i * len(fits) + j] = samples[:, i]\n",
    "            lines[i * (len(fits) + 1) + j] = samples[:, i].mean()\n",
    "    xs = [None if y is None else i * xscale for i, y in enumerate(lines)]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(xs, lines, \"k-\", alpha=0.2)\n",
    "    props = {\"linewidth\": 0.5}\n",
    "    boxplot = plt.boxplot(data, positions=positions, vert=True, patch_artist=True,\n",
    "                          showfliers=False,\n",
    "                          boxprops=props, whiskerprops=props, capprops=props,\n",
    "                          medianprops={\"alpha\": 0})\n",
    "    colors = ['lightblue', 'pink', 'lightgreen']\n",
    "    for i, patch in enumerate(boxplot['boxes']):\n",
    "        patch.set_facecolor(colors[i % len(fits)])\n",
    "    for name, c in zip(fits, colors):\n",
    "        plt.plot([], label=name, marker=\"s\", color=c)\n",
    "    plt.legend(loc=\"best\", prop={'size': 10})\n",
    "    start = (len(fits) - 1) / 2\n",
    "    plt.xticks(torch.linspace(start, start + (top_k - 1) * (len(fits) + 1), top_k) * xscale,\n",
    "               labels=top_lineages, rotation=-90)\n",
    "    plt.ylabel(\"$R / R_A$\")\n",
    "    plt.title(f\"Top {top_k} lineages with highest growth rate\")\n",
    "    for f in filenames:\n",
    "        plt.savefig(f)\n",
    "\n",
    "for name in [\"Europe\"]:\n",
    "    name_ = name.lower().replace(\" \", \"_\")\n",
    "    plot_strain_subset_boxplot({\n",
    "        f\"World w/o {name}\": holdout_fits[f\"excluding {name}\"],\n",
    "        \"World\": best_fit,\n",
    "        f\"{name} only\": holdout_fits[f\"only {name}\"],\n",
    "    }, filenames=[f\"paper/strain_{name_}_boxplot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
